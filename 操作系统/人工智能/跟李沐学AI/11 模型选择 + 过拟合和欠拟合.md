### 训练误差和泛化误差
* 训练误差： 模型在训练数据上的误差
* 泛化误差： 模型在新数据上的误差(我们更关心的)
* 例子： 根据模考成绩来预测未来考试分数
  * 在过去考试表现好(训练误差)不代表考试一定会好(泛化误差)
---
### 验证数据集和测试数据集
* 验证数据集：一个用来评估模型好坏的数据集，选择模型超参数
   * 例如拿出50%的训练数据
   * 一定不要跟训练数据混在一起 ！！！
   * 如果不注意，验证数据集可能虚高，因为你的超参数很有可能是在验证数据集上调出来的。

* 测试数据集：只用一次的数据集，不能够来调你的超参数！！！
   * 例如未来的考试
   * 我出价的房子的实际成交价
   * 用过一次，不会再看你下一次的结果了。
---


### K-则交叉验证
> 在没有足够多数据时使用。
>
算法：
1. 将训练数据分割成 K 块.
2. For i = 1,....K
   * 使用第 i 块作为验证数据集，其余作为训练数据集
3. 报告 K 个验证集误差的平均。

---
### 过拟合和欠拟合
<div align="center">
<img src=过拟合欠拟合.jpg width=50%>
</div>

根据数据集的简单或复杂来选择对应的模型的容量。
   
数据简单->选择低的模型容量,若使用复杂模型容量，会出现过拟合。

### 模型容量
* 拟合各种函数的能力。
* 低容量的模型难以拟合训练数据
* 高容量的模型可以记住所有的训练数据

<div align="center">
<img src=模型容量的影响.jpg width=50%>
</div>

1. 模型容量较低的时候，无法拟合较复杂的数据，泛化误差也高。
2. 数据里面有大量的噪音，模型过于关注细节。
3. 中间的gap来衡量过拟合和欠拟合的程度。
4. 首先模型容量得足够大，再通过某种手段控制容量，使得泛化误差往下降。
5. 模型容量一般和参数个数，参数的取值范围有关。

### VC维——统计学习理论的核心思想
> 对于一个分类模型， VC等于一个最大的数据集大小，不管如何给定标号，都存在一个模型来对它进行完美分类。