## Evaluation

你选择的具体评估取决于你想要模型具有什么样的功能。关于评估，这里有一个简单的框架：

1. What are the **inputs**?
2. How do **call** the language model?
3. How do you evaluate the **outputs**?
4. How to **interpret** the results?



## Perplexity

困惑度本质上衡量了语言模型对某个数据集赋予高概率的程度。

首先，我们知道一个语言模型可以给一个文本序列赋予一个概率。这个文本序列就是我们的**数据集 D**。假设数据集 D 包含一系列词语（token），比如 w1,w2,…,wN，其中∣D∣= N 是词语的总数。

语言模型会计算这个序列出现的总概率，即 p(D)=p(w1,w2,…,wN)。根据概率论的链式法则，这个总概率可以分解为每个词语在其前面所有词语出现的情况下，出现的**条件概率**的乘积：

p(D)=p(w1)×p(w2∣w1)×p(w3∣w1,w2)×⋯×p(wN∣w1,…,wN−1)

- p(w1) 是第一个词语出现的概率。
- p(w2∣w1) 是在已知第一个词语是 w1 的情况下，第二个词语是 w2 的概率。
- 以此类推，每个项都代表了模型对“下一个词语是什么”的预测。

**一个好的语言模型会给这个真实数据集赋予一个很高的概率值 p(D)。**

#### 困惑度公式的直观含义

现在我们回到困惑度公式：
$$
(\frac{1}{p(D)})^{\frac{1}{|D|}}
$$

- **逆概率$\frac{1}{p(D)}$**：概率 $\frac{1}{p(D)}$越小，$\frac{1}{p(D)}$ 就越大。这可以理解为模型对整个数据集的“不确定性”或“惊讶程度”。
- **平均数$\frac{1}{|D|}$** :这相当于将整个数据集的“不确定性”**平均分配到了每个词语上**。

所以，**困惑度可以被直观地理解为语言模型在预测下一个词时，平均有多少种“备选项”**。

- 如果困惑度是 100，这就像是模型在预测每一个词时，平均有 100 个同样可能的词供它选择。
- 如果困惑度是 10，那么平均只有 10 个可能的词。

很显然，**备选项越少，模型的预测能力越强，也说明模型对这个数据集“越不困惑”**。

过去，研究者们通常在一个标准数据集上进行训练，然后在同一个数据集的测试集上进行评估。这是一种“同分布（in-distribution）”评估。GPT-2在一个非常庞大且多样化的数据集 WebText上进行训练，然后**在标准数据集上进行“零样本（zero-shot）”评估**。这是一种**“分布外（out-of-distribution）”评估**。这种方法验证了大型模型在海量数据上训练后，可以具备强大的泛化能力。

自 **GPT-2 和 GPT-3** 之后，语言模型的研究重心从单纯追求低困惑度**转向了下游任务（downstream task）的准确率**。

尽管风向变了，但困惑度并非过时，它在某些方面仍然非常有用。

* 平滑性（Smoother）： 困惑度的曲线比下游任务的准确率曲线更平滑，这使得它非常适合用来研究模型的**“缩放定律（scaling laws）”**，即模型规模（参数量、数据量）与性能之间的关系。

* 普适性（Universal）：困惑度是一个通用的指标，因为它衡量的是模型对语言本身的理解，而任务准确率可能无法捕捉到所有的细微差别。

* 条件困惑度（Conditional Perplexity）：笔记提到，我们也可以测量特定下游任务的“条件困惑度”，这结合了困惑度的优点和任务导向的评估。



## Knowledge Bechmarks

### **Massive Multitask Language Understanding (MMLU)**

MMLU是一个用于评估大型语言模型（LLMs）能力的基准测试。包含57个不同主题的多任务集合。



### **Graduate-Level Google-Proof Q&A (GPQA)**

GPQA (Graduate-Level Google-Proof Q&A) 是一个用于评估大型语言模型（LLMs）的基准测试，它旨在衡量模型在回答需要深入理解和推理的复杂科学问题方面的能力。些问题是由61位拥有博士学位（或正在攻读博士）的专家撰写的，他们来自生物学、物理学和化学等领域。这确保了问题的专业性和挑战性。



### Humanity's Last Exam

“Humanity's Last Exam” (人类的最后一场考试) 是一个专门为评估大型语言模型（LLMs）而设计的基准测试，被认为是目前最全面、最具挑战性的测试之一。目前，即使是顶尖的AI模型，在这个测试上的得分也相对较低。



## Instruction Following Bechmarks







