## LLM.Int8()

型语言模型（如拥有1750亿参数的模型）的推理需要大量的GPU内存 。尽管以前有使用 8 位量化的方法来减少内存，但它们通常会导致性能下降，并且只适用于参数量较小的模型（小于3.5亿） 。当模型规模超过 67 亿参数时，一个称为“异常特征”（outlier features）的现象会突然出现，这些特征会破坏量化精度，导致模型性能严重下降。

虽然输入数据 X 中的激活值是动态变化的，但在LLM中**产生异常值的维度（也就是列）是相对固定的**。比如说某一层的隐藏状态$X \in R^{s\times h}$，$s$是序列长度，$h$是隐藏层的维度，下面但是 $h_2$ 这一列（feature 维度 2）的数值比较大，这就是 **outlier feature**。不光$h_2$在这一层比较显著，在其层级这个$h_2$一般也会比较大，所以说这个产生异常的维度是相对固定的。

![](./img/LLMInt8()-1.jpg)

那么如何找出这些outlier features呢？论文采用了一种经验性的方法来识别这些异常维度。他们在模型量化前，通过一小部分校准数据集来分析激活值。outlier feature要满足下面这几个条件：

>1. 该特征的幅度至少有一次大于阈值（论文中取$\alpha=6.0$）
>2. 该特征维度在至少25%的模型层中出现异常值
>3. 该特征维度在至少6%的序列维度中出现异常值

在找出所有的outlier features后，就把LLM中的矩阵乘法（MLP层，QKV的投影层）进行分解，具体如下所示：

![](./img/LLMInt8().jpg)
